{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prepared word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\dkohn\\AppData\\Local\\Anaconda3.5\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gc import collect\n",
    "\n",
    "from helper import score_prediction\n",
    "from benchmarkNet import simpleCNN\n",
    "from pubmed import load_prepared_train_data, load_prepared_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pubmed + PMC + Wikipedia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and test set:\n",
    "* with maxlen=200 and enmbedding length=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training set\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data/word_vectors/wiki_pubmed_PMC_maxlen100_embeddinglen200_'\n",
    "X_train, y_train = load_prepared_train_data(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put data into a simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36925 samples, validate on 4103 samples\n",
      "Epoch 1/10\n",
      "36925/36925 [==============================] - 146s - loss: 2.3778 - acc: 0.2720 - val_loss: 1.8666 - val_acc: 0.3995\n",
      "Epoch 2/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.9619 - acc: 0.3843 - val_loss: 1.6954 - val_acc: 0.4326\n",
      "Epoch 3/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.8080 - acc: 0.4154 - val_loss: 1.6375 - val_acc: 0.4463\n",
      "Epoch 4/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.7010 - acc: 0.4380 - val_loss: 1.6069 - val_acc: 0.4487\n",
      "Epoch 5/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.6320 - acc: 0.4528 - val_loss: 1.5936 - val_acc: 0.4502\n",
      "Epoch 6/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.5705 - acc: 0.4673 - val_loss: 1.5901 - val_acc: 0.4516\n",
      "Epoch 7/10\n",
      "36925/36925 [==============================] - 149s - loss: 1.5111 - acc: 0.4790 - val_loss: 1.6096 - val_acc: 0.4455\n",
      "Epoch 8/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.4620 - acc: 0.4897 - val_loss: 1.5913 - val_acc: 0.4499\n",
      "Epoch 9/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.4180 - acc: 0.4967 - val_loss: 1.6052 - val_acc: 0.4455\n",
      "Epoch 10/10\n",
      "36925/36925 [==============================] - 147s - loss: 1.3825 - acc: 0.5029 - val_loss: 1.6156 - val_acc: 0.4387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x9a53fc1eb8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = simpleCNN() # from benchmarkNet.py\n",
    "model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test set and calculate accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        36\n",
      "          1       0.35      0.59      0.44       182\n",
      "          2       0.48      0.77      0.59       457\n",
      "          3       0.37      0.46      0.41       254\n",
      "          4       0.50      0.45      0.48       241\n",
      "          5       0.20      0.21      0.20        63\n",
      "          6       0.46      0.77      0.57        81\n",
      "          7       0.36      0.67      0.47       126\n",
      "          8       0.29      0.25      0.27       106\n",
      "          9       0.35      0.61      0.44       232\n",
      "         10       0.38      0.49      0.43       140\n",
      "         11       0.36      0.38      0.37        84\n",
      "         12       0.48      0.78      0.59       523\n",
      "         13       0.39      0.57      0.46       331\n",
      "         14       0.40      0.51      0.45       143\n",
      "         15       0.21      0.43      0.28        37\n",
      "         16       0.51      0.77      0.61        30\n",
      "         17       0.29      0.10      0.15       771\n",
      "         18       0.35      0.44      0.39       218\n",
      "         19       0.45      0.45      0.45       132\n",
      "         20       0.48      0.31      0.38        45\n",
      "         21       0.47      0.57      0.52       235\n",
      "         22       0.24      0.43      0.31        92\n",
      "\n",
      "avg / total       0.39      0.49      0.41      4559\n",
      "\n",
      "Accuracy: 29.52%\n",
      "AUC: 0.92\n",
      "Accurray:  0.295240184251\n"
     ]
    }
   ],
   "source": [
    "# delete train set\n",
    "del X_train, y_train\n",
    "collect()\n",
    "# load test data\n",
    "X_test, y_test = load_prepared_test_data(file_name)\n",
    "# perform prediction\n",
    "yhat = model.predict(X_test)\n",
    "acc = score_prediction(y_test, yhat, binary=False)\n",
    "print('Accurray: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete all object for the next task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_test, y_test, model, yhat, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pubmed + PMC (without Wikipedia)\n",
    "Load training and test set:\n",
    "* with maxlen=200 and enmbedding length=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training set\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data/word_vectors/pubmed_PMC_maxlen100_embeddinglen200_'\n",
    "X_train, y_train = load_prepared_train_data(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run model and calculate accuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36925 samples, validate on 4103 samples\n",
      "Epoch 1/10\n",
      "36925/36925 [==============================] - 146s - loss: 2.3500 - acc: 0.2853 - val_loss: 1.8253 - val_acc: 0.4117\n",
      "Epoch 2/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.9411 - acc: 0.3829 - val_loss: 1.7006 - val_acc: 0.4380\n",
      "Epoch 3/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.7916 - acc: 0.4185 - val_loss: 1.6467 - val_acc: 0.4511\n",
      "Epoch 4/10\n",
      "36925/36925 [==============================] - 147s - loss: 1.6960 - acc: 0.4435 - val_loss: 1.6046 - val_acc: 0.4516\n",
      "Epoch 5/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.6117 - acc: 0.4581 - val_loss: 1.5885 - val_acc: 0.4528\n",
      "Epoch 6/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.5542 - acc: 0.4701 - val_loss: 1.5897 - val_acc: 0.4492\n",
      "Epoch 7/10\n",
      "36925/36925 [==============================] - 147s - loss: 1.4976 - acc: 0.4809 - val_loss: 1.5763 - val_acc: 0.4519\n",
      "Epoch 8/10\n",
      "36925/36925 [==============================] - 147s - loss: 1.4484 - acc: 0.4892 - val_loss: 1.5813 - val_acc: 0.4433\n",
      "Epoch 9/10\n",
      "36925/36925 [==============================] - 147s - loss: 1.4045 - acc: 0.5002 - val_loss: 1.5846 - val_acc: 0.4426\n",
      "Epoch 10/10\n",
      "36925/36925 [==============================] - 149s - loss: 1.3636 - acc: 0.5114 - val_loss: 1.6332 - val_acc: 0.4338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x9a54e19f60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = simpleCNN() # from benchmarkNet.py\n",
    "model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        36\n",
      "          1       0.35      0.59      0.44       182\n",
      "          2       0.49      0.70      0.58       457\n",
      "          3       0.39      0.54      0.45       254\n",
      "          4       0.52      0.47      0.50       241\n",
      "          5       0.21      0.16      0.18        63\n",
      "          6       0.49      0.65      0.56        81\n",
      "          7       0.36      0.40      0.38       126\n",
      "          8       0.30      0.26      0.28       106\n",
      "          9       0.41      0.43      0.42       232\n",
      "         10       0.39      0.34      0.36       140\n",
      "         11       0.40      0.32      0.36        84\n",
      "         12       0.53      0.63      0.57       523\n",
      "         13       0.43      0.48      0.46       331\n",
      "         14       0.41      0.50      0.45       143\n",
      "         15       0.27      0.41      0.33        37\n",
      "         16       0.57      0.70      0.63        30\n",
      "         17       0.28      0.09      0.14       771\n",
      "         18       0.35      0.35      0.35       218\n",
      "         19       0.48      0.39      0.43       132\n",
      "         20       0.50      0.29      0.37        45\n",
      "         21       0.49      0.61      0.55       235\n",
      "         22       0.29      0.15      0.20        92\n",
      "\n",
      "avg / total       0.41      0.43      0.40      4559\n",
      "\n",
      "Accuracy: 43.04%\n",
      "Accurray:  0.430357534547\n"
     ]
    }
   ],
   "source": [
    "# delete train data\n",
    "del X_train, y_train\n",
    "collect()\n",
    "# load test data\n",
    "X_test, y_test = load_prepared_test_data(file_name)\n",
    "# perform prediction\n",
    "yhat = model.predict(X_test)\n",
    "acc = score_prediction(y_test, yhat, binary=False)\n",
    "print('Accurray: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_test, y_test, model, yhat, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pubmed only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training set\n",
      "Train on 36925 samples, validate on 4103 samples\n",
      "Epoch 1/10\n",
      "36925/36925 [==============================] - 150s - loss: 2.3379 - acc: 0.2778 - val_loss: 1.7909 - val_acc: 0.4248\n",
      "Epoch 2/10\n",
      "36925/36925 [==============================] - 154s - loss: 1.9217 - acc: 0.3936 - val_loss: 1.6963 - val_acc: 0.4402\n",
      "Epoch 3/10\n",
      "36925/36925 [==============================] - 152s - loss: 1.7699 - acc: 0.4261 - val_loss: 1.6127 - val_acc: 0.4541\n",
      "Epoch 4/10\n",
      "36925/36925 [==============================] - 155s - loss: 1.6728 - acc: 0.4456 - val_loss: 1.5759 - val_acc: 0.4519\n",
      "Epoch 5/10\n",
      "36925/36925 [==============================] - 158s - loss: 1.5967 - acc: 0.4606 - val_loss: 1.5644 - val_acc: 0.4599\n",
      "Epoch 6/10\n",
      "36925/36925 [==============================] - 153s - loss: 1.5393 - acc: 0.4729 - val_loss: 1.5743 - val_acc: 0.4489\n",
      "Epoch 7/10\n",
      "36925/36925 [==============================] - 178s - loss: 1.4726 - acc: 0.4852 - val_loss: 1.5659 - val_acc: 0.4536\n",
      "Epoch 8/10\n",
      "36925/36925 [==============================] - 157s - loss: 1.4205 - acc: 0.4964 - val_loss: 1.5711 - val_acc: 0.4531\n",
      "Epoch 9/10\n",
      "36925/36925 [==============================] - 160s - loss: 1.3855 - acc: 0.5051 - val_loss: 1.6199 - val_acc: 0.4467\n",
      "Epoch 10/10\n",
      "36925/36925 [==============================] - 152s - loss: 1.3402 - acc: 0.5132 - val_loss: 1.6281 - val_acc: 0.4385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x9a54fff898>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'data/word_vectors/pubmed_maxlen100_embeddinglen200_'\n",
    "X_train, y_train = load_prepared_train_data(file_name)\n",
    "model = simpleCNN() # from benchmarkNet.py\n",
    "model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.10      0.03      0.04        36\n",
      "          1       0.38      0.46      0.41       182\n",
      "          2       0.51      0.70      0.59       457\n",
      "          3       0.40      0.45      0.42       254\n",
      "          4       0.54      0.44      0.48       241\n",
      "          5       0.31      0.19      0.24        63\n",
      "          6       0.50      0.73      0.59        81\n",
      "          7       0.35      0.40      0.37       126\n",
      "          8       0.25      0.24      0.24       106\n",
      "          9       0.41      0.54      0.46       232\n",
      "         10       0.37      0.45      0.40       140\n",
      "         11       0.33      0.36      0.34        84\n",
      "         12       0.48      0.74      0.58       523\n",
      "         13       0.47      0.46      0.47       331\n",
      "         14       0.41      0.50      0.45       143\n",
      "         15       0.32      0.46      0.38        37\n",
      "         16       0.48      0.73      0.58        30\n",
      "         17       0.33      0.09      0.14       771\n",
      "         18       0.34      0.39      0.36       218\n",
      "         19       0.46      0.47      0.47       132\n",
      "         20       0.50      0.29      0.37        45\n",
      "         21       0.55      0.43      0.48       235\n",
      "         22       0.42      0.14      0.21        92\n",
      "\n",
      "avg / total       0.42      0.43      0.41      4559\n",
      "\n",
      "Accuracy: 43.47%\n",
      "Accurray:  0.434744461505\n"
     ]
    }
   ],
   "source": [
    "# delete train data\n",
    "del X_train, y_train\n",
    "collect()\n",
    "# load test data\n",
    "X_test, y_test = load_prepared_test_data(file_name)\n",
    "# perform prediction\n",
    "# perform prediction\n",
    "yhat = model.predict(X_test)\n",
    "acc = score_prediction(y_test, yhat, binary=False)\n",
    "print('Accurray: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_test, y_test, model, yhat, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMC only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training set\n",
      "Train on 36925 samples, validate on 4103 samples\n",
      "Epoch 1/10\n",
      "36925/36925 [==============================] - 160s - loss: 2.4187 - acc: 0.2719 - val_loss: 1.9360 - val_acc: 0.3670\n",
      "Epoch 2/10\n",
      "36925/36925 [==============================] - 154s - loss: 2.0085 - acc: 0.3731 - val_loss: 1.7489 - val_acc: 0.4216\n",
      "Epoch 3/10\n",
      "36925/36925 [==============================] - 153s - loss: 1.8549 - acc: 0.4081 - val_loss: 1.6848 - val_acc: 0.4316\n",
      "Epoch 4/10\n",
      "36925/36925 [==============================] - 152s - loss: 1.7448 - acc: 0.4290 - val_loss: 1.6463 - val_acc: 0.4392\n",
      "Epoch 5/10\n",
      "36925/36925 [==============================] - 151s - loss: 1.6747 - acc: 0.4440 - val_loss: 1.6222 - val_acc: 0.4455\n",
      "Epoch 6/10\n",
      "36925/36925 [==============================] - 148s - loss: 1.6035 - acc: 0.4600 - val_loss: 1.6175 - val_acc: 0.4480\n",
      "Epoch 7/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.5441 - acc: 0.4739 - val_loss: 1.6125 - val_acc: 0.4416\n",
      "Epoch 8/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.4969 - acc: 0.4795 - val_loss: 1.6022 - val_acc: 0.4394\n",
      "Epoch 9/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.4560 - acc: 0.4898 - val_loss: 1.6382 - val_acc: 0.4290\n",
      "Epoch 10/10\n",
      "36925/36925 [==============================] - 146s - loss: 1.4068 - acc: 0.4988 - val_loss: 1.6762 - val_acc: 0.4255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x9a567ea390>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'data/word_vectors/PMC_maxlen100_embeddinglen200_'\n",
    "X_train, y_train = load_prepared_train_data(file_name)\n",
    "model = simpleCNN() # from benchmarkNet.py\n",
    "model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        36\n",
      "          1       0.35      0.42      0.38       182\n",
      "          2       0.45      0.81      0.58       457\n",
      "          3       0.38      0.41      0.39       254\n",
      "          4       0.55      0.40      0.46       241\n",
      "          5       0.20      0.10      0.13        63\n",
      "          6       0.45      0.65      0.54        81\n",
      "          7       0.36      0.38      0.37       126\n",
      "          8       0.32      0.25      0.28       106\n",
      "          9       0.39      0.44      0.41       232\n",
      "         10       0.42      0.39      0.40       140\n",
      "         11       0.35      0.33      0.34        84\n",
      "         12       0.50      0.74      0.60       523\n",
      "         13       0.41      0.46      0.43       331\n",
      "         14       0.42      0.46      0.44       143\n",
      "         15       0.29      0.41      0.34        37\n",
      "         16       0.49      0.70      0.58        30\n",
      "         17       0.28      0.10      0.15       771\n",
      "         18       0.36      0.31      0.34       218\n",
      "         19       0.42      0.43      0.43       132\n",
      "         20       0.44      0.24      0.31        45\n",
      "         21       0.54      0.40      0.46       235\n",
      "         22       0.34      0.17      0.23        92\n",
      "\n",
      "avg / total       0.40      0.42      0.39      4559\n",
      "\n",
      "Accuracy: 42.22%\n",
      "Accurray:  0.422241719675\n"
     ]
    }
   ],
   "source": [
    "# delete train data\n",
    "#del X_train, y_train\n",
    "#collect()\n",
    "# load test data\n",
    "X_test, y_test = load_prepared_test_data(file_name)\n",
    "# perform prediction\n",
    "# perform prediction\n",
    "yhat = model.predict(X_test)\n",
    "acc = score_prediction(y_test, yhat, binary=False)\n",
    "print('Accurray: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_test, y_test, model, yhat, acc"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
