{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPool1D, Dropout, Dense, Reshape\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from keras import metrics\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fasttext facebook\n",
    "PubMed PMC word vectors\n",
    "Gensim word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_train, target_train = helper.load_multiclass_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_test, ids_test = helper.load_binary_data(\"data/test_binary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfIdf-BoW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45587, 33714)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(binary=False, max_df=0.9, min_df=3, lowercase=True, strip_accents=\"unicode\")\n",
    "count_vect.fit(documents_train)\n",
    "pickle.dump(count_vect, open(\"models/valentin/vectorizer.p\", \"wb\"))\n",
    "X_train_counts = count_vect.transform(documents_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_shape=(X.shape[1],), activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 0\n",
      "Loop 1\n",
      "Loop 2\n",
      "Loop 3\n",
      "Loop 4\n",
      "Loop 5\n",
      "Loop 6\n",
      "Loop 7\n",
      "Loop 8\n",
      "Loop 9\n",
      "Average Accuracy: 95.69%\n",
      "[0.96759259259259256, 0.95833333333333337, 0.96296296296296291, 0.95370370370370372, 0.94907407407407407, 0.96759259259259256, 0.97222222222222221, 0.94907407407407407, 0.93055555555555558, 0.95833333333333337]\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(10):\n",
    "    print(\"Loop {}\".format(str(i)))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.1)\n",
    "    model = create_model()\n",
    "    model.fit(X_train.todense(), y_train, validation_split=0.1, epochs=20, verbose=0)\n",
    "    yhat = model.predict(X_test.todense())\n",
    "    acc_i = helper.score_prediction(y_test, yhat, acc_only=True)\n",
    "    acc.append(acc_i)\n",
    "\n",
    "print(\"Average Accuracy: {:.2%}\".format(np.mean(acc)))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98       103\n",
      "          1       1.00      0.96      0.98       113\n",
      "\n",
      "avg / total       0.98      0.98      0.98       216\n",
      "\n",
      "Accuracy: 97.69%\n",
      "AUC: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f25c0072860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = model.predict(X_test.todense())\n",
    "helper.score_prediction(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_submission = count_vect.transform(documents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.fit(X.todense(), target_train.values, epochs=20, verbose=1)\n",
    "model.evaluate(X.todense(), target_train.values)\n",
    "yhat = model.predict(X_submission.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper.create_binary_submission(yhat, ids_test, \"submissions/valentin/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_train, target_train = helper.load_multiclass_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoplist = list(gensim.parsing.preprocessing.STOPWORDS) + [\"<span\"] + list(range(0,9))\n",
    "def word_is_valid(word):\n",
    "    return word not in stoplist and len(word) > 2 and len(word) < 20\n",
    "\n",
    "texts = [[word for word in document.lower().split() if word_is_valid(word)] for document in documents_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(180083 unique tokens: ['insulinlike', 'growth', 'factor', 'associated', 'diabetic']...)\n",
      "Dictionary(46109 unique tokens: ['insulinlike', 'growth', 'factor', 'associated', 'diabetic']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "print(dictionary)\n",
    "dictionary.filter_extremes(no_above=0.9)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token2id = dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [[token2id.get(word) for word in text if token2id.get(word, False)] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 1000\n",
    "X_sequential = sequence.pad_sequences(corpus, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sequential, target_train.values, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_embedding_cnn_model(output_dim=1):\n",
    "    embedding_dim = 100\n",
    "    filters = 250\n",
    "    kernel_size = 3\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(token2id), output_dim=embedding_dim, input_length=maxlen))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "    # we use max pooling:\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36925 samples, validate on 4103 samples\n",
      "Epoch 1/10\n",
      "36925/36925 [==============================] - 16s - loss: 2.8714 - acc: 0.1612 - val_loss: 2.7717 - val_acc: 0.1723\n",
      "Epoch 2/10\n",
      "36925/36925 [==============================] - 16s - loss: 2.5878 - acc: 0.1700 - val_loss: 2.5065 - val_acc: 0.1723\n",
      "Epoch 3/10\n",
      "36925/36925 [==============================] - 16s - loss: 2.3302 - acc: 0.2128 - val_loss: 2.3145 - val_acc: 0.2854\n",
      "Epoch 4/10\n",
      "36925/36925 [==============================] - 16s - loss: 2.1478 - acc: 0.3191 - val_loss: 2.1929 - val_acc: 0.3939\n",
      "Epoch 5/10\n",
      "36925/36925 [==============================] - 16s - loss: 2.0078 - acc: 0.3870 - val_loss: 2.0895 - val_acc: 0.4248\n",
      "Epoch 6/10\n",
      "36925/36925 [==============================] - 17s - loss: 1.9130 - acc: 0.4128 - val_loss: 1.9956 - val_acc: 0.4265\n",
      "Epoch 7/10\n",
      "36925/36925 [==============================] - 17s - loss: 1.8186 - acc: 0.4391 - val_loss: 1.9307 - val_acc: 0.4311\n",
      "Epoch 8/10\n",
      "36925/36925 [==============================] - 16s - loss: 1.7451 - acc: 0.4511 - val_loss: 1.9113 - val_acc: 0.4268\n",
      "Epoch 9/10\n",
      "36925/36925 [==============================] - 16s - loss: 1.6866 - acc: 0.4646 - val_loss: 1.8890 - val_acc: 0.4275\n",
      "Epoch 10/10\n",
      "36925/36925 [==============================] - 17s - loss: 1.6329 - acc: 0.4770 - val_loss: 1.8389 - val_acc: 0.4265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b7f3b6e48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_embedding_cnn_model(output_dim=23)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        38\n",
      "          1       0.30      0.48      0.37       188\n",
      "          2       0.53      0.64      0.58       479\n",
      "          3       0.43      0.48      0.45       229\n",
      "          4       0.52      0.49      0.50       226\n",
      "          5       0.00      0.00      0.00        69\n",
      "          6       0.40      0.54      0.46        71\n",
      "          7       0.46      0.53      0.49       153\n",
      "          8       1.00      0.01      0.02       103\n",
      "          9       0.42      0.58      0.49       267\n",
      "         10       0.29      0.24      0.26       122\n",
      "         11       0.36      0.04      0.07        98\n",
      "         12       0.48      0.66      0.55       485\n",
      "         13       0.40      0.44      0.42       312\n",
      "         14       0.48      0.56      0.52       163\n",
      "         15       0.24      0.08      0.12        63\n",
      "         16       1.00      0.09      0.17        33\n",
      "         17       0.26      0.18      0.22       789\n",
      "         18       0.36      0.44      0.40       216\n",
      "         19       0.43      0.48      0.45       122\n",
      "         20       0.00      0.00      0.00        44\n",
      "         21       0.46      0.59      0.52       214\n",
      "         22       0.17      0.03      0.05        75\n",
      "\n",
      "avg / total       0.40      0.42      0.39      4559\n",
      "\n",
      "Accuracy: 41.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/bin/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "_ = helper.score_prediction(y_test, yhat, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import gc\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_train, target_train = helper.load_multiclass_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('data/wikipedia-pubmed-and-PMC-w2v.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_length = 200\n",
    "default = np.zeros(embedding_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(word):\n",
    "    global no_hit\n",
    "    try:\n",
    "        return word_vectors.word_vec(word)\n",
    "    except KeyError as e:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = list(gensim.parsing.preprocessing.STOPWORDS) + [\"<span\"] + list(range(0,9))\n",
    "def word_is_valid(word):\n",
    "    return word not in stoplist and len(word) > 2 and len(word) < 20\n",
    "\n",
    "texts = [np.array([np.transpose(word2vec(word)) for word in \n",
    "          tokenizer.tokenize(document.lower()) if word_is_valid(word)]) for document in documents_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del word_vectors\n",
    "del documents_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "def pad_or_trunc(doc):\n",
    "    if len(doc) < maxlen:\n",
    "        return np.concatenate((doc, np.zeros((maxlen-len(doc), 200))))\n",
    "    else:\n",
    "        return doc[:maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_padded = np.array([pad_or_trunc(text) for text in texts])\n",
    "del texts\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45587, 100, 200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(texts, open(\"data/multiclass_w2v.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts_padded, target_train.values, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del texts_padded\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(output_dim=1):\n",
    "    input_shape = (maxlen, embedding_length)\n",
    "    filters = 250\n",
    "    kernel_size = 3\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1, input_shape=input_shape))\n",
    "    # we use max pooling:\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36925 samples, validate on 4103 samples\n",
      "Epoch 1/10\n",
      "36925/36925 [==============================] - 8s - loss: 2.5511 - acc: 0.2330 - val_loss: 2.3091 - val_acc: 0.3193\n",
      "Epoch 2/10\n",
      "36925/36925 [==============================] - 4s - loss: 2.1793 - acc: 0.3157 - val_loss: 2.0619 - val_acc: 0.3731\n",
      "Epoch 3/10\n",
      "36925/36925 [==============================] - 4s - loss: 2.0242 - acc: 0.3613 - val_loss: 1.9810 - val_acc: 0.4238\n",
      "Epoch 4/10\n",
      "36925/36925 [==============================] - 4s - loss: 1.9488 - acc: 0.3857 - val_loss: 1.9292 - val_acc: 0.4407\n",
      "Epoch 5/10\n",
      "36925/36925 [==============================] - 4s - loss: 1.8901 - acc: 0.4028 - val_loss: 1.8636 - val_acc: 0.4499\n",
      "Epoch 6/10\n",
      "36925/36925 [==============================] - 4s - loss: 1.8371 - acc: 0.4188 - val_loss: 1.8096 - val_acc: 0.4467\n",
      "Epoch 7/10\n",
      "36925/36925 [==============================] - 4s - loss: 1.8197 - acc: 0.4238 - val_loss: 1.7602 - val_acc: 0.4450\n",
      "Epoch 8/10\n",
      "36925/36925 [==============================] - 4s - loss: 1.7909 - acc: 0.4298 - val_loss: 1.7622 - val_acc: 0.4567\n",
      "Epoch 9/10\n",
      "36925/36925 [==============================] - 4s - loss: 1.7646 - acc: 0.4343 - val_loss: 1.7333 - val_acc: 0.4560\n",
      "Epoch 10/10\n",
      "36925/36925 [==============================] - 4s - loss: 1.7503 - acc: 0.4375 - val_loss: 1.7380 - val_acc: 0.4641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5cc251ef60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_cnn_model(output_dim=23)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        36\n",
      "          1       0.41      0.52      0.46       182\n",
      "          2       0.52      0.79      0.62       457\n",
      "          3       0.43      0.51      0.47       254\n",
      "          4       0.58      0.46      0.51       241\n",
      "          5       0.11      0.02      0.03        63\n",
      "          6       0.51      0.75      0.61        81\n",
      "          7       0.43      0.47      0.45       126\n",
      "          8       0.45      0.16      0.24       106\n",
      "          9       0.38      0.63      0.48       232\n",
      "         10       0.49      0.25      0.33       140\n",
      "         11       0.47      0.20      0.28        84\n",
      "         12       0.51      0.74      0.61       523\n",
      "         13       0.53      0.45      0.49       331\n",
      "         14       0.36      0.55      0.44       143\n",
      "         15       0.34      0.41      0.37        37\n",
      "         16       0.51      0.77      0.61        30\n",
      "         17       0.29      0.14      0.18       771\n",
      "         18       0.39      0.47      0.43       218\n",
      "         19       0.52      0.48      0.50       132\n",
      "         20       0.82      0.20      0.32        45\n",
      "         21       0.53      0.54      0.54       235\n",
      "         22       0.29      0.07      0.11        92\n",
      "\n",
      "avg / total       0.44      0.46      0.43      4559\n",
      "\n",
      "Accuracy: 45.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/bin/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "_ = helper.score_prediction(y_test, yhat, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
