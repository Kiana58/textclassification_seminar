{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named keras.models",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-731af46249aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalMaxPool1D\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMaxPool1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalMaxPool2D\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named keras.models"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, Conv2D, GlobalMaxPool1D,MaxPool1D, GlobalMaxPool2D,Dropout, Dense, Reshape, Flatten\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from keras import metrics\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fasttext facebook\n",
    "PubMed PMC word vectors\n",
    "Gensim word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_train, target_train = helper.load_multiclass_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_test, ids_test = helper.load_binary_data(\"data/test_binary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfIdf-BoW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45587, 33714)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(binary=False, max_df=0.9, min_df=3, lowercase=True, strip_accents=\"unicode\")\n",
    "count_vect.fit(documents_train)\n",
    "pickle.dump(count_vect, open(\"models/valentin/vectorizer.p\", \"wb\"))\n",
    "X_train_counts = count_vect.transform(documents_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_shape=(X.shape[1],), activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 0\n",
      "Loop 1\n",
      "Loop 2\n",
      "Loop 3\n",
      "Loop 4\n",
      "Loop 5\n",
      "Loop 6\n",
      "Loop 7\n",
      "Loop 8\n",
      "Loop 9\n",
      "Average Accuracy: 95.69%\n",
      "[0.96759259259259256, 0.95833333333333337, 0.96296296296296291, 0.95370370370370372, 0.94907407407407407, 0.96759259259259256, 0.97222222222222221, 0.94907407407407407, 0.93055555555555558, 0.95833333333333337]\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(10):\n",
    "    print(\"Loop {}\".format(str(i)))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.1)\n",
    "    model = create_model()\n",
    "    model.fit(X_train.todense(), y_train, validation_split=0.1, epochs=20, verbose=0)\n",
    "    yhat = model.predict(X_test.todense())\n",
    "    acc_i = helper.score_prediction(y_test, yhat, acc_only=True)\n",
    "    acc.append(acc_i)\n",
    "\n",
    "print(\"Average Accuracy: {:.2%}\".format(np.mean(acc)))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98       103\n",
      "          1       1.00      0.96      0.98       113\n",
      "\n",
      "avg / total       0.98      0.98      0.98       216\n",
      "\n",
      "Accuracy: 97.69%\n",
      "AUC: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f25c0072860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = model.predict(X_test.todense())\n",
    "helper.score_prediction(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_submission = count_vect.transform(documents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.fit(X.todense(), target_train.values, epochs=20, verbose=1)\n",
    "model.evaluate(X.todense(), target_train.values)\n",
    "yhat = model.predict(X_submission.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper.create_binary_submission(yhat, ids_test, \"submissions/valentin/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_train, target_train = helper.load_multiclass_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoplist = list(gensim.parsing.preprocessing.STOPWORDS) + [\"<span\"] + list(range(0,9))\n",
    "def word_is_valid(word):\n",
    "    return word not in stoplist and len(word) > 2 and len(word) < 20\n",
    "\n",
    "texts = [[word for word in document.lower().split() if word_is_valid(word)] for document in documents_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(180083 unique tokens: ['insulinlike', 'growth', 'factor', 'associated', 'diabetic']...)\n",
      "Dictionary(46109 unique tokens: ['insulinlike', 'growth', 'factor', 'associated', 'diabetic']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "print(dictionary)\n",
    "dictionary.filter_extremes(no_above=0.9)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token2id = dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [[token2id.get(word) for word in text if token2id.get(word, False)] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 1000\n",
    "X_sequential = sequence.pad_sequences(corpus, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sequential, target_train.values, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_embedding_cnn_model(output_dim=1):\n",
    "    embedding_dim = 100\n",
    "    filters = 250\n",
    "    kernel_size = 3\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(token2id), output_dim=embedding_dim, input_length=maxlen))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "    # we use max pooling:\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36925 samples, validate on 4103 samples\n",
      "Epoch 1/10\n",
      "36925/36925 [==============================] - 16s - loss: 2.8714 - acc: 0.1612 - val_loss: 2.7717 - val_acc: 0.1723\n",
      "Epoch 2/10\n",
      "36925/36925 [==============================] - 16s - loss: 2.5878 - acc: 0.1700 - val_loss: 2.5065 - val_acc: 0.1723\n",
      "Epoch 3/10\n",
      "36925/36925 [==============================] - 16s - loss: 2.3302 - acc: 0.2128 - val_loss: 2.3145 - val_acc: 0.2854\n",
      "Epoch 4/10\n",
      "36925/36925 [==============================] - 16s - loss: 2.1478 - acc: 0.3191 - val_loss: 2.1929 - val_acc: 0.3939\n",
      "Epoch 5/10\n",
      "36925/36925 [==============================] - 16s - loss: 2.0078 - acc: 0.3870 - val_loss: 2.0895 - val_acc: 0.4248\n",
      "Epoch 6/10\n",
      "36925/36925 [==============================] - 17s - loss: 1.9130 - acc: 0.4128 - val_loss: 1.9956 - val_acc: 0.4265\n",
      "Epoch 7/10\n",
      "36925/36925 [==============================] - 17s - loss: 1.8186 - acc: 0.4391 - val_loss: 1.9307 - val_acc: 0.4311\n",
      "Epoch 8/10\n",
      "36925/36925 [==============================] - 16s - loss: 1.7451 - acc: 0.4511 - val_loss: 1.9113 - val_acc: 0.4268\n",
      "Epoch 9/10\n",
      "36925/36925 [==============================] - 16s - loss: 1.6866 - acc: 0.4646 - val_loss: 1.8890 - val_acc: 0.4275\n",
      "Epoch 10/10\n",
      "36925/36925 [==============================] - 17s - loss: 1.6329 - acc: 0.4770 - val_loss: 1.8389 - val_acc: 0.4265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b7f3b6e48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_embedding_cnn_model(output_dim=23)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        38\n",
      "          1       0.30      0.48      0.37       188\n",
      "          2       0.53      0.64      0.58       479\n",
      "          3       0.43      0.48      0.45       229\n",
      "          4       0.52      0.49      0.50       226\n",
      "          5       0.00      0.00      0.00        69\n",
      "          6       0.40      0.54      0.46        71\n",
      "          7       0.46      0.53      0.49       153\n",
      "          8       1.00      0.01      0.02       103\n",
      "          9       0.42      0.58      0.49       267\n",
      "         10       0.29      0.24      0.26       122\n",
      "         11       0.36      0.04      0.07        98\n",
      "         12       0.48      0.66      0.55       485\n",
      "         13       0.40      0.44      0.42       312\n",
      "         14       0.48      0.56      0.52       163\n",
      "         15       0.24      0.08      0.12        63\n",
      "         16       1.00      0.09      0.17        33\n",
      "         17       0.26      0.18      0.22       789\n",
      "         18       0.36      0.44      0.40       216\n",
      "         19       0.43      0.48      0.45       122\n",
      "         20       0.00      0.00      0.00        44\n",
      "         21       0.46      0.59      0.52       214\n",
      "         22       0.17      0.03      0.05        75\n",
      "\n",
      "avg / total       0.40      0.42      0.39      4559\n",
      "\n",
      "Accuracy: 41.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/bin/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "_ = helper.score_prediction(y_test, yhat, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkohn\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import pickle\n",
    "\n",
    "os.chdir('C:/Users/dkohn/Documents/kaggle/textclassification_seminar')\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents_train, target_train = helper.load_multiclass_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('data/wikipedia-pubmed-and-PMC-w2v.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_length = 200\n",
    "default = np.zeros(embedding_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "no_hit = ()\n",
    "def word2vec(word):\n",
    "    global no_hit\n",
    "    try:\n",
    "        return word_vectors.word_vec(word)\n",
    "    except KeyError as e:\n",
    "        no_hit = no_hit + (word,)\n",
    "        return default\n",
    "print(len(no_hit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoplist = list(gensim.parsing.preprocessing.STOPWORDS) + [\"<span\"] + list(range(0,9))\n",
    "def word_is_valid(word):\n",
    "    return word not in stoplist and len(word) > 2 and len(word) < 20\n",
    "\n",
    "texts = [np.array([np.transpose(word2vec(word)) for word in \n",
    "          tokenizer.tokenize(document.lower()) if word_is_valid(word)]) for document in documents_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del word_vectors\n",
    "del documents_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "def pad_or_trunc(doc):\n",
    "    if len(doc) < maxlen:\n",
    "        return np.concatenate((doc, np.zeros((maxlen-len(doc), 200))))\n",
    "    else:\n",
    "        return doc[:maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_padded = np.array([pad_or_trunc(text) for text in texts])\n",
    "del texts\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45587, 100, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts_padded, target_train.values, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del texts_padded\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(output_dim=1):\n",
    "    input_shape = (maxlen, embedding_length)\n",
    "    filters = 400\n",
    "    kernel_size = (7)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(400,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1, input_shape=input_shape))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36925 samples, validate on 4103 samples\n",
      "Epoch 1/10\n",
      "36925/36925 [==============================] - 6s - loss: 2.3636 - acc: 0.2701 - val_loss: 1.8714 - val_acc: 0.3970\n",
      "Epoch 2/10\n",
      "36925/36925 [==============================] - 5s - loss: 1.9523 - acc: 0.3824 - val_loss: 1.6929 - val_acc: 0.4428\n",
      "Epoch 3/10\n",
      "36925/36925 [==============================] - 5s - loss: 1.8029 - acc: 0.4173 - val_loss: 1.6566 - val_acc: 0.4446\n",
      "Epoch 4/10\n",
      "36925/36925 [==============================] - 5s - loss: 1.7007 - acc: 0.4377 - val_loss: 1.6209 - val_acc: 0.4511\n",
      "Epoch 5/10\n",
      "36925/36925 [==============================] - 5s - loss: 1.6214 - acc: 0.4548 - val_loss: 1.5884 - val_acc: 0.4506\n",
      "Epoch 6/10\n",
      "36925/36925 [==============================] - 6s - loss: 1.5645 - acc: 0.4667 - val_loss: 1.6001 - val_acc: 0.4477\n",
      "Epoch 7/10\n",
      "36925/36925 [==============================] - 6s - loss: 1.5101 - acc: 0.4792 - val_loss: 1.5763 - val_acc: 0.4487\n",
      "Epoch 8/10\n",
      "36925/36925 [==============================] - 6s - loss: 1.4601 - acc: 0.4875 - val_loss: 1.6034 - val_acc: 0.4409\n",
      "Epoch 9/10\n",
      "36925/36925 [==============================] - 6s - loss: 1.4144 - acc: 0.4993 - val_loss: 1.5947 - val_acc: 0.4487\n",
      "Epoch 10/10\n",
      "36925/36925 [==============================] - 6s - loss: 1.3727 - acc: 0.5077 - val_loss: 1.6021 - val_acc: 0.4326\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.09      0.03      0.04        36\n",
      "          1       0.34      0.54      0.42       182\n",
      "          2       0.53      0.68      0.59       457\n",
      "          3       0.38      0.52      0.44       254\n",
      "          4       0.53      0.46      0.49       241\n",
      "          5       0.20      0.08      0.11        63\n",
      "          6       0.51      0.70      0.59        81\n",
      "          7       0.35      0.46      0.40       126\n",
      "          8       0.37      0.22      0.27       106\n",
      "          9       0.38      0.55      0.45       232\n",
      "         10       0.38      0.38      0.38       140\n",
      "         11       0.32      0.30      0.31        84\n",
      "         12       0.52      0.63      0.57       523\n",
      "         13       0.42      0.52      0.46       331\n",
      "         14       0.44      0.49      0.46       143\n",
      "         15       0.29      0.49      0.36        37\n",
      "         16       0.49      0.60      0.54        30\n",
      "         17       0.33      0.07      0.12       771\n",
      "         18       0.37      0.47      0.41       218\n",
      "         19       0.45      0.38      0.41       132\n",
      "         20       0.46      0.40      0.43        45\n",
      "         21       0.51      0.54      0.53       235\n",
      "         22       0.32      0.20      0.24        92\n",
      "\n",
      "avg / total       0.42      0.43      0.40      4559\n",
      "\n",
      "Accuracy: 43.39%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_cnn_model(output_dim=23)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=256)\n",
    "yhat = model.predict(X_test)\n",
    "_ = helper.score_prediction(y_test, yhat, binary=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_train, target_train = helper.load_binary_data()\n",
    "word_vectors = KeyedVectors.load_word2vec_format('data/wikipedia-pubmed-and-PMC-w2v.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_length = 200\n",
    "default = np.zeros(embedding_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "no_hit = ()\n",
    "def word2vec(word):\n",
    "    global no_hit\n",
    "    try:\n",
    "        return word_vectors.word_vec(word)\n",
    "    except KeyError as e:\n",
    "        no_hit = no_hit + (word,)\n",
    "        return default\n",
    "print(len(no_hit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoplist = list(gensim.parsing.preprocessing.STOPWORDS) + [\"<span\"] + list(range(0,9))\n",
    "def word_is_valid(word):\n",
    "    return word not in stoplist and len(word) > 2 and len(word) < 20\n",
    "\n",
    "texts = [np.array([np.transpose(word2vec(word)) for word in \n",
    "          tokenizer.tokenize(document.lower()) if word_is_valid(word)]) for document in documents_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 100\n",
    "def pad_or_trunc(doc):\n",
    "    if len(doc) < maxlen:\n",
    "        return np.concatenate((doc, np.zeros((maxlen-len(doc), 200))))\n",
    "    else:\n",
    "        return doc[:maxlen]\n",
    "texts_padded = np.array([pad_or_trunc(text) for text in texts])\n",
    "del texts\n",
    "del word_vectors\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2155, 100, 200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts_padded, target_train.values, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(output_dim=1):\n",
    "    input_shape = (maxlen, embedding_length)\n",
    "    filters = 100\n",
    "    kernel_size = (7)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1, input_shape=input_shape))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1745 samples, validate on 194 samples\n",
      "Epoch 1/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.5100 - acc: 0.7685 - val_loss: 0.2852 - val_acc: 0.9433\n",
      "Epoch 2/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.3343 - acc: 0.8911 - val_loss: 0.2105 - val_acc: 0.9536\n",
      "Epoch 3/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.2548 - acc: 0.9221 - val_loss: 0.1681 - val_acc: 0.9588\n",
      "Epoch 4/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.2314 - acc: 0.9226 - val_loss: 0.1577 - val_acc: 0.9536\n",
      "Epoch 5/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.1986 - acc: 0.9347 - val_loss: 0.1380 - val_acc: 0.9588\n",
      "Epoch 6/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.1742 - acc: 0.9513 - val_loss: 0.1263 - val_acc: 0.9536\n",
      "Epoch 7/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.1576 - acc: 0.9553 - val_loss: 0.1266 - val_acc: 0.9588\n",
      "Epoch 8/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.1487 - acc: 0.9519 - val_loss: 0.1116 - val_acc: 0.9485\n",
      "Epoch 9/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.1243 - acc: 0.9679 - val_loss: 0.1104 - val_acc: 0.9485\n",
      "Epoch 10/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0955 - acc: 0.9742 - val_loss: 0.1329 - val_acc: 0.9536\n",
      "Epoch 11/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0990 - acc: 0.9708 - val_loss: 0.1089 - val_acc: 0.9536\n",
      "Epoch 12/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0710 - acc: 0.9834 - val_loss: 0.1116 - val_acc: 0.9588\n",
      "Epoch 13/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0654 - acc: 0.9862 - val_loss: 0.1315 - val_acc: 0.9433\n",
      "Epoch 14/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0654 - acc: 0.9794 - val_loss: 0.1112 - val_acc: 0.9639\n",
      "Epoch 15/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0476 - acc: 0.9908 - val_loss: 0.1230 - val_acc: 0.9485\n",
      "Epoch 16/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0387 - acc: 0.9943 - val_loss: 0.1232 - val_acc: 0.9485\n",
      "Epoch 17/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0355 - acc: 0.9948 - val_loss: 0.1195 - val_acc: 0.9536\n",
      "Epoch 18/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0302 - acc: 0.9937 - val_loss: 0.1101 - val_acc: 0.9691\n",
      "Epoch 19/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0323 - acc: 0.9908 - val_loss: 0.1174 - val_acc: 0.9639\n",
      "Epoch 20/20\n",
      "1745/1745 [==============================] - 0s - loss: 0.0240 - acc: 0.9960 - val_loss: 0.1397 - val_acc: 0.9485\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.90      0.93       107\n",
      "          1       0.91      0.97      0.94       109\n",
      "\n",
      "avg / total       0.94      0.94      0.94       216\n",
      "\n",
      "Accuracy: 93.52%\n",
      "AUC: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7193"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7fd9f2908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_cnn_model(output_dim=1)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_split=0.1, epochs=20, batch_size=256)\n",
    "yhat = model.predict(X_test)\n",
    "_ = helper.score_prediction(y_test, yhat, binary=True)\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
